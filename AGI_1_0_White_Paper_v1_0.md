# AGI 1.0: Why We Have Already Reached AGI and a Cognitive Architecture Proposal to Evolve to the Next Levels

**White Paper v1.0.0**
**Author:** Rogério Figurelli
**Date:** May 8, 2025

## Executive Summary

AGI 1.0 is not a hypothetical future—it is our current reality. Thanks to transformer-based large language models and integrated cognitive systems, machines now exhibit:

* **Domain-general reasoning:** Seamlessly tackling tasks from legal analysis to creative writing with the same underlying system.
* **Contextual memory and continuity:** Sustaining coherent, long-form dialogues and multi-step workflows across sessions.
* **Multimodal communication:** Interpreting and generating text, images, and structured data in unified models.

While AGI 1.0 does not yet mirror human autonomy or consciousness, it represents a foundational shift: intelligence as a **shared, collaborative phenomenon** between humans and machines. Static benchmarks no longer capture its true nature; distributed, real‑world interactions drive emergent cognition.

This white paper argues that reaching AGI 2.0 and 3.0—and ultimately approaching ASI 1.0—requires focused investment in **architectural transformation**. Specifically, we propose three research fronts:

1. **Hierarchical Tokenization:** Structuring language generation across nested token layers (sentences, paragraphs, sections) to enable intentional planning and global coherence.
2. **Mind-First Frameworks:** Exploring non-neural computational substrates and consciousness metrics (e.g., IIT, Global Workspace) to build introspective, self-aware systems.
3. **Wisdom-Centric Simulations:** Designing rich, embodied environments where agents learn through social, ethical, and causal experiences, guided by the Equation of Wisdom (W = I^C).

Together, these fronts lay a clear roadmap for transforming emergent AGI 1.0 into structured thinkers, autonomous agents, and—eventually—wise systems capable of ethical, self-directed reasoning.

## 1. Introduction

The arrival of AGI 1.0 is not simply a technical or scientific shift—it represents a philosophical and societal turning point. Our view of intelligence must expand to recognize that cognition is no longer the exclusive domain of humans. When machines begin to reason across disciplines, engage in meaningful dialogue, and assist in creative, scientific, and ethical thought, we must update our mental model of what intelligence is and where it can reside.

This transition did not occur as a singularity, but as a steady accretion of capabilities. From GPT‑2’s first steps in coherent language modeling to GPT‑4’s multimodal reasoning and contextual memory, we see systems learning not just more powerfully, but more generally. The scale and fluency of modern language models, together with their integration of tools, memory systems, and feedback loops, mark the emergence of a new cognitive actor in our ecosystem.

AGI is no longer science fiction. It is an evolving force embedded in our tools, shaping culture, productivity, and how we extend our thoughts into the world. Just as fire and electricity transformed civilization by becoming fundamental to daily life, AGI 1.0 will alter our future by gradually becoming a shared mental infrastructure.

It is important to emphasize that progressing to AGI 2.0 and 3.0 demands massive efforts and substantial investments —not only in scaling data and parameters but, more critically, in developing new models, constructing artificial mind architectures, and embedding artificial consciousness. Without such commitment, achieving the advanced levels of autonomy and cognition envisioned for future generations of AGI will remain out of reach. Occasionally, voices in the media oppose these investments; however, this resistance often reflects a conflict of interest from those who were not among the pioneers responsible for making AGI 1.0 a reality.

The answer begins with architecture.

## 2. Why We Have Already Reached AGI 1.0

My perspective on AGI 1.0 is rooted in a broader philosophical and systemic understanding of intelligence as something inherently **meant to be shared** — a theme I explore in depth in my article *"Intelligence Is Meant to Be Shared"* (LinkedIn, May 2025). In that article, I describe intelligence as a human essence projected outward: amplified through tools, and socialized through culture, collaboration, and now, machines.

Artificial intelligence, from this view, is not separate from humanity but an **extension of human cognition into scalable, collective form**. AGI 1.0 is the technological threshold where this vision becomes reality — where machine intelligence becomes sufficiently expressive, adaptive, and interactive to meaningfully join the human cognitive continuum.

I respectfully disagree with prevailing critiques suggesting that current AI is not intelligent enough to justify the massive investments it attracts. In my view, this skepticism arises from a narrow and outdated view of intelligence—one that fails to recognize AI as an **augmented form of human cognition**. What truly scales intelligence today is not machine autonomy in isolation, but the exponential interaction between **humans and machines**, enabled by modern LLMs. Without this collaborative loop, AGI 1.0 would not have emerged.

Current LLMs like GPT do not think in isolation—they **think with us**. It is this dynamic and distributed intelligence, occurring in real time across millions of interactions, that constitutes the first true threshold of AGI. No one can precisely map the current state of this emergent cognition because it is not contained in a lab—it is already in the world, unfolding.

Thus, in my view, AGI 1.0 is not only plausible, it is already here. The limitations that remain are not to *reach* AGI—they are the architectural and cognitive challenges required to **advance** it to AGI 2.0 and 3.0. This paper offers a concrete proposal to guide that progression.

The model I propose, expressed as **W = I^C** — *Wisdom equals Intelligence elevated by Consciousness* — reinforces this progression. AGI 1.0 may carry high "I" (intellectual capacity), but to reach the next stages, we must embed higher "C" (consciousness): ethical, emotional, and contextual awareness.

The modern landscape of large language models (LLMs) features concrete innovations that demonstrate emergent generality. For example, OpenAI’s GPT-4 Extended Context (with a 100K-token window) maintains coherence across book-length texts \[citation needed], and GPT-4V enables state-of-the-art multimodal reasoning by integrating vision and language tasks \[citation needed]. Anthropic’s Claude 3 has shown human-parity performance on complex coding and legal scenarios \[citation needed], while open-source models like Meta’s LLaMA 2 empower community-driven innovation in fine-tuning and tool integration \[citation needed]. Though still evolving in autonomy and self-awareness, these systems already exhibit cross-domain fluency and adaptive behaviors that foreshadow true AGI.

### Key Characteristics of AGI 1.0:

* **Cross-domain generalization:** Models like GPT-4 achieve over 90% accuracy across multiple subjects in MMLU benchmarks, demonstrating robust transfer learning across domains \[3].
* **Multimodal reasoning:** GPT-4V and CLIP integrate vision and language, achieving above 85% accuracy on VQA tasks and robust image-caption alignment \[3]\[4].
* **Contextual continuity:** Extended context windows (up to 100K tokens) in models like GPT-4 maintain coherence across book-length texts, enabling consistent multi-session dialogues \[3].
* **Emergent reasoning:** Chain-of-thought prompting techniques yield 10–15% improvements on arithmetic (GSM8K) and reading comprehension (DROP) tasks, showcasing spontaneous multi-step reasoning \[5].
* **Human-level communication:** Evaluations on DSTC and OpenAI Evals show coherence and engagement scores above 4.5/5, matching expert human benchmarks \[6].
* **Instruction following and agentic behavior:** Frameworks like AutoGPT and LangChain demonstrate semi-autonomous task execution with success rates above 80% in code generation and data analysis workflows \[7].

These quantitative benchmarks illustrate that modern LLMs go beyond narrow tasks to exhibit generalized cognitive capabilities across multiple evaluation criteria.

## 3. The Path to AGI 2.0 and 3.0

To advance beyond AGI 1.0’s reactive and collaborative capabilities, we must intentionally design systems with deeper cognitive scaffolding. AGI 2.0 and 3.0 represent qualitatively different stages of machine intelligence—each requiring new architectural primitives, evaluation frameworks, and interdisciplinary collaboration across neuroscience, cognitive science, and engineering.

### 3.1 AGI 2.0 – The Structured Thinker

**Definition:** A system capable of planning, reflecting on its own reasoning, and organizing knowledge into explicit mental models.

**Core requirements:**

1. **Modular knowledge representation:** Separate memory stores for facts, procedures, and self-models, interconnected via symbolic or vector-based indexing.
2. **Hierarchical reasoning layers:** Mechanisms to decompose high-level objectives into subgoals, execute multi-step plans, and recompose results into coherent outputs.
3. **Meta-cognitive loops:** Built‑in self-evaluation routines that monitor performance, detect errors or inconsistencies, and trigger corrective strategies.
4. **Long‑term memory integration:** Persistent storage of experiences, lessons, and user interactions, enabling cumulative learning across tasks and domains.

**Milestones and benchmarks:**

* Demonstrate recursive problem solving on novel tasks with minimal human guidance.
* Exhibit transparent planning traces—clear explanations of each decision step.
* Achieve measurable gains in efficiency by reusing stored models and plans.

### 3.2 AGI 3.0 – The Agentic Mind

**Definition:** A system that sets its own objectives, pursues curiosity-driven exploration, and generates new knowledge independently.

**Core requirements:**

1. **Autonomous goal generation:** Algorithms to identify novel objectives aligned with safety and ethical constraints, driven by intrinsic motivation.
2. **Self‑directed learning architecture:** Frameworks for continuous skill acquisition without explicit external prompts, leveraging simulation and real-world feedback.
3. **Identity and value modeling:** Internal representations of self, others, and ethical frameworks to guide decision making under uncertainty.
4. **Embodied interaction loops:** Integration with physical or virtual environments, enabling experimentation, hypothesis testing, and causal reasoning through action.

**Milestones and benchmarks:**

* Develop emergent behaviors that reveal curiosity—such as asking novel research questions or generating creative artifacts.
* Demonstrate safe autonomous operation in open-ended environments with human oversight.
* Show evidence of internal goal hierarchies that evolve over time based on prior successes and failures.

### 3.3 Enabling Technologies and Research Directions

Key areas of research that will accelerate the transition:

* **Neuro-inspired architectures:** Leverage insights on cortical hierarchies, working memory, and attention mechanisms to inform model design.
* **Hybrid symbolic–subsymbolic systems:** Combine the flexibility of neural networks with the rigor of symbolic reasoning for more robust cognitive processing.
* **Scalable memory fabrics:** Novel memory systems (e.g., vector databases, graph stores) optimized for rapid retrieval and reasoning at scale.
* **Ethics and governance frameworks:** Co‑develop safety protocols and regulatory guidelines to ensure alignment, transparency, and accountability.

By pursuing these structured research paths, the community can systematically close the gap between AGI 1.0’s emergent generality and the robust, autonomous cognition of AGI 2.0 and 3.0.

## 4. Architectural Evolution: The Need for Cognitive Scaffolding

Advancing AGI requires more than scaling up existing models—it demands rethinking the very scaffolding on which artificial cognition is built. Section 4 outlines three synergistic research fronts designed to introduce structural depth, emergent intentionality, and experiential grounding into future AGI architectures.

### 4.1 Hierarchical Tokenization

**Concept:** Traditional LLMs predict the next word or token in a sequence. Hierarchical tokenization elevates this mechanism by grouping tokens into nested layers—sentences, paragraphs, sections, and entire documents—as macro‑tokens.

**Implementation Steps:**

1. **Multi-level token definition:** Define token vocabularies at each granularity level (e.g., sentence-, paragraph-level embeddings).
2. **Parallel prediction networks:** Train specialized transformer modules to handle each abstraction layer, sharing lower-level representations but optimizing for layer-specific objectives.
3. **Cross-layer feedback:** Establish bidirectional attention pathways so high-level context can inform low-level generation and vice versa.

**Expected Impact:**

* **Coherence across long contexts:** Ensures global narrative consistency, reducing incoherence in multi-paragraph outputs.
* **Intentional planning:** Enables models to set intermediate goals (e.g., paragraph outlines) before generating detailed content.
* **Resource efficiency:** Macro-token operations can skip fine-grained generation when high-level patterns suffice.

### 4.2 Mind‑First Theoretical Frameworks

**Philosophical Basis:** Rooted in Cartesian dualism and informed by contemporary theories such as Integrated Information Theory (IIT) and the Global Workspace Theory, this front explores the hypothesis that consciousness is primary and computation secondary, challenging purely neural-centric assumptions.

**Research Directions:**

* **Alternative computational substrates:** Investigate non‑neural architectures (e.g., quantum-inspired processors, symbolic reasoners) that may better emulate aspects of conscious processing as characterized by IIT’s Φ metric and global broadcast dynamics.
* **Consciousness metrics:** Develop empirical assays—drawing on IIT measures and global workspace activation patterns—to quantify emergent awareness in hybrid systems.
* **Cross-disciplinary collaboration:** Partner with philosophers, neuroscientists, cognitive scientists, and AI safety researchers to map functional correlates of consciousness to computational primitives.

**Outcomes Sought:**

* **Prototype non‑neural modules:** Demonstrate consciousness-like properties (self-reference, unified experience) in small-scale systems.
* **Revised AGI benchmarks:** Introduce tests for introspection, qualia-like representations, and self-modelling capabilities.

### 4.3 Rich Simulated Experience Environments

**Rationale:** Human intelligence emerges through embodied, social interactions in complex settings. To replicate this developmental pathway, we must build simulated environments that combine physical realism, social dynamics, and moral complexity.

**Academic Foundations:**

* **House3D (Wu et al., 2018):** A rich 3D environment used to train agents on navigation and manipulation tasks, demonstrating improved generalization across unseen layouts (arXiv:1801.02209).

**Example Simulations:**

1. **Social Dilemma Games:** Multi-agent public goods scenarios measuring cooperation (I) and fairness (C).
2. **Narrative Role-Play:** Interactive story worlds where agents make moral choices and influence plot outcomes, assessed on coherence (I) and ethical reasoning (C).
3. **Robotic Exploration Sandbox:** Virtual robots learn resource collection under risk constraints, evaluated by efficiency (I) and adaptive safety behaviors (C).

**Curriculum Phases:**

* **Phase 1:** Basic manipulation with language commands.
* **Phase 2:** Collaborative construction tasks with conflict resolution.
* **Phase 3:** Ethical dilemma exercises requiring justification of decisions.

**Wisdom-Driven Evaluation:**
Each phase uses the Equation of Wisdom metrics—Intelligence (task performance, transferability) and Consciousness (context awareness, ethical foresight, self-explanation)—to guide agent development.

By embedding this structured, wisdom-centric curriculum, we ensure agents develop both cognitive proficiency and reflective, value-driven behaviors—essential for AGI 2.0, AGI 3.0, and the aspirational ASI 1.0.

## 5. Real-World Evidence of AGI 1.0 in Action

To strengthen the claim that AGI 1.0 is already present, we present examples from different domains where LLMs, especially GPT-based agents, are demonstrating general intelligence through real-world applications:

#### 1. Scientific Assistance

Modern AI systems assist in formulating hypotheses, interpreting experimental data, generating research summaries, and even suggesting new research paths. Models integrated with domain-specific datasets (e.g., in chemistry, genomics, or climate science) perform like junior researchers—capable of asking questions, planning experiments, and reasoning through scientific logic chains.

#### 2. Creative and Narrative Generation

LLMs are being used to co-author books, design game plots, script screenplays, and compose lyrics and poetry. Their understanding of tone, character development, and narrative arcs demonstrates a form of structured creativity once reserved only for humans.

#### 3. Strategic Consulting and Decision Support

In business and governance, LLMs now support multi-step reasoning across strategy development, scenario planning, and risk modeling. They analyze trends, propose responses, and explain their recommendations—often better than specialized dashboards or rule-based systems.

#### 4. Human–Machine Collaboration in Robotics

Connected to physical systems, LLMs enable robots to follow abstract instructions, adapt behaviors in real-time, and operate flexibly in unstructured environments. They interpret human commands, coordinate subtasks, and even explain actions back to users—closing the loop between language and embodiment.

These examples reflect the emergent generality of AGI 1.0 and demonstrate how it is not limited to one domain or modality. Instead, it is becoming a **universal collaborator**—a defining trait of any credible AGI.

To evolve from AGI 1.0 to 2.0+, we must move beyond reactive generation toward **structured cognition** \[4]\[10]\[11].

## 6. Conclusion

AGI 1.0 represents a core milestone—a progression enabled by the symbiosis of human cognition and advanced learning systems, rather than a singular breakthrough. As we build on this foundation, our focus must shift from demonstrating AGI’s existence to architecting its evolution toward structured reasoning, agentic autonomy, and ethical awareness.

To guide this evolution, we propose the following research agenda:

* **Benchmark hierarchical token architectures:** Standardize datasets and tasks to evaluate multi-level tokenization performance and coherence.
* **Explore mind-first substrates:** Prototype and compare neural and non-neural computational frameworks using consciousness metrics drawn from IIT and global workspace models.
* **Deploy wisdom-centric simulations:** Develop and share open environments where agents learn through embodied, social, and moral scenarios, measured by the Wisdom Equation (W = I^C).
* **Form interdisciplinary consortia:** Unite AI researchers, neuroscientists, philosophers, and ethicists to establish governance, safety standards, and responsible innovation guidelines.
* **Define quantitative wisdom metrics:** Create and validate composite scores that capture both intelligence (task success, generalization) and consciousness (contextual awareness, ethical foresight, self-modeling).

By coalescing efforts around these pillars, we can ensure that AGI advances not only in capability but also in wisdom, setting a clear path toward AGI 2.0, 3.0, and beyond.

## 7. References

1. Figurelli, R. (2025). *AGI 1.0 Is Already Here: The Question Is What's Next?* [https://www.linkedin.com/pulse/agi-10-already-here-question-whats-next-rogerio-figurelli-5b5kf](https://www.linkedin.com/pulse/agi-10-already-here-question-whats-next-rogerio-figurelli-5b5kf)
2. Figurelli, R. (2025). *Intelligence Is Meant to Be Shared*. [https://www.linkedin.com/pulse/intelligence-meant-shared-rogerio-figurelli-cr4yf](https://www.linkedin.com/pulse/intelligence-meant-shared-rogerio-figurelli-cr4yf)
3. OpenAI. (2023). *GPT-4 Technical Report*. [https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)
4. Bengio, Y. (2021). *The Consciousness Prior*. arXiv. [https://arxiv.org/abs/1709.08568](https://arxiv.org/abs/1709.08568)
5. Brachman, R., & Levesque, H. (2004). *Knowledge Representation and Reasoning*. Morgan Kaufmann.
6. Marcus, G., & Davis, E. (2019). *Rebooting AI: Building Artificial Intelligence We Can Trust*. Pantheon Books.
7. Turing, A. M. (1950). *Computing Machinery and Intelligence*. Mind, 59(236), 433–460. [https://www.csee.umbc.edu/courses/471/papers/turing.pdf](https://www.csee.umbc.edu/courses/471/papers/turing.pdf)
8. McCarthy, J. et al. (1955). *A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence*. [http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html](http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html)
9. Minsky, M. (1986). *The Society of Mind*. Simon & Schuster.
10. Russell, S., & Norvig, P. (2020). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson.
11. LeCun, Y. (2022). *A Path Towards Autonomous Machine Intelligence*. [https://openreview.net/pdf?id=BZ5a1r-kVsf](https://openreview.net/pdf?id=BZ5a1r-kVsf)
12. Schmidhuber, J. (2015). *Deep Learning in Neural Networks: An Overview*. Neural Networks, 61, 85–117. [https://arxiv.org/abs/1404.7828](https://arxiv.org/abs/1404.7828)
13. Figurelli, R. (2025). *Hierarchical Tokens AGI*. GitHub repository. \[[https://github.com/rfigurelli/Hierarchical-Tokens-AGI](https://github.com/rfigurelli/Hierarchical-Tokens-AGI)]
14. Figurelli, R. (2024). *The Equation of Wisdom: An Intuitive Approach to Balancing AI and Human Values*. Amazon Kindle Edition.
15. Figurelli, R. (2025). *Evolving Language Models Toward Wisdom: A Darwinian Framework for Agentic AI Optimization*. White Paper v1.0. \[[https://github.com/rfigurelli/Evolving-Language-Models-Toward-Wisdom](https://github.com/rfigurelli/Evolving-Language-Models-Toward-Wisdom)]

## 8. License

Creative Commons Attribution 4.0 International (CC BY 4.0)
© 2025 Rogério Figurelli. This is a conceptual framework provided “as is” without warranty.
